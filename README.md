# Bad Apple sur Shadertoy - Guide Complet

Projet de compression vidÃ©o procÃ©durale pour [Shadertoy.com](https://www.shadertoy.com) utilisant un **rÃ©seau de neurones Tiny** embarquÃ© directement dans le code GLSL (pas de texture custom).

## ğŸ¯ Concept

Bad Apple (480Ã—360, 6572 frames, 1.08 GB) â†’ RÃ©seau de neurones Tiny (4353 paramÃ¨tres, 17 KB) â†’ Shader GLSL multi-pass sur Shadertoy

**Approche** : Un NN qui apprend la fonction `f(frame, x, y) â†’ pixel_value` et reconstruit la vidÃ©o en temps rÃ©el.

## ğŸš€ Quick Start

### 1. Installer les dÃ©pendances

```bash
uv sync
# ou
pip install -e .
```

### 2. EntraÃ®ner le rÃ©seau de neurones

```bash
python3 bad_apple/train_nn.py
```

**DurÃ©e** : 
- CPU: ~1-2 heures
- GPU: ~10-15 minutes

**Sortie** :
- `bad_apple/nn_weights_tiny.npz` - Poids du rÃ©seau
- `bad_apple/nn_weights_tiny_metadata.json` - MÃ©tadonnÃ©es

### 3. GÃ©nÃ©rer le shader Shadertoy

```bash
python3 generate_shadertoy_multipass.py bad_apple/nn_weights_tiny.npz
```

**Sortie** :
- `bad_apple/shadertoy_buffer_a.glsl` - Buffer A (stockage des poids)
- `bad_apple/shadertoy_image.glsl` - Image (infÃ©rence NN)
- `bad_apple/SHADERTOY_SETUP.md` - Instructions dÃ©taillÃ©es

### 4. Upload sur Shadertoy

1. **CrÃ©er un nouveau shader** : https://www.shadertoy.com/new

2. **Ajouter Buffer A** :
   - Cliquer "+" â†’ "Buf A"
   - Copier le contenu de `shadertoy_buffer_a.glsl`
   - Coller dans l'onglet "Buf A"

3. **Configurer Image** :
   - Aller dans l'onglet "Image"
   - Cliquer sur **iChannel0** â†’ SÃ©lectionner **"Buf A"**
   - Copier le contenu de `shadertoy_image.glsl`
   - Coller dans l'onglet "Image"

4. **Compiler** : Alt+Enter

5. ğŸ‰ **La vidÃ©o devrait jouer !**

## ğŸ“ Structure du projet

```
shadertoys/
â”œâ”€â”€ bad_apple/
â”‚   â”œâ”€â”€ video.webm                      # VidÃ©o source (480Ã—360, 6572 frames)
â”‚   â”œâ”€â”€ video_pixels.parquet            # Pixels extraits (1.08 GB)
â”‚   â”œâ”€â”€ train_nn.py                     # EntraÃ®nement NN Tiny
â”‚   â”œâ”€â”€ nn_weights_tiny.npz             # Poids entraÃ®nÃ©s (gÃ©nÃ©rÃ©)
â”‚   â”œâ”€â”€ shadertoy_buffer_a.glsl         # Shader Buffer A (gÃ©nÃ©rÃ©)
â”‚   â”œâ”€â”€ shadertoy_image.glsl            # Shader Image (gÃ©nÃ©rÃ©)
â”‚   â””â”€â”€ SHADERTOY_SETUP.md              # Instructions (gÃ©nÃ©rÃ©)
â”œâ”€â”€ generate_shadertoy_multipass.py     # GÃ©nÃ©rateur shader multi-pass
â”œâ”€â”€ extract_pixels.py                   # Extraction pixels â†’ Parquet
â”œâ”€â”€ pyproject.toml                      # DÃ©pendances
â””â”€â”€ README.md                           # Ce fichier
```

## ğŸ§  Architecture du rÃ©seau

**Tiny NN** : `[3] â†’ [32] â†’ [64] â†’ [32] â†’ [1]`

- **Input** : `(frame_norm, x_norm, y_norm)` âˆˆ [0, 1]Â³
- **Hidden** : 3 couches fully-connected avec ReLU
- **Output** : `pixel_value` âˆˆ [0, 1] via Sigmoid
- **ParamÃ¨tres** : 4,353 (~17 KB)

**Training** :
- Sample rate : 5% des pixels (~57M pixels)
- Batch size : 8192
- Epochs : 30
- Loss : MSE
- Optimizer : Adam (lr=0.001)

## ğŸ“Š RÃ©sultats attendus

| MÃ©trique | Valeur |
|----------|--------|
| **Compression** | ~60,000x (1.08 GB â†’ 17 KB) |
| **QualitÃ©** | â­â­ Acceptable mais floue |
| **PSNR** | ~20-25 dB |
| **Performance** | ğŸŒ Lent (calcul per-pixel) |
| **Code size** | ~10-15K caractÃ¨res GLSL |

**QualitÃ©** : Le rÃ©seau est intentionnellement trÃ¨s petit pour tenir dans le code Shadertoy. La vidÃ©o sera reconnaissable mais floue/pixelisÃ©e. C'est un proof-of-concept, pas une compression haute fidÃ©litÃ©.

## âš™ï¸ Configuration avancÃ©e

### Augmenter la qualitÃ© (sacrifie la taille)

Ã‰diter `bad_apple/train_nn.py` :

```python
architectures = [
    {
        "name": "Tiny",
        "hidden": [64, 128, 64],  # Plus gros rÃ©seau
        "sample_rate": 0.1,        # Plus de donnÃ©es
        "epochs": 50,              # Plus d'entraÃ®nement
        "batch_size": 4096,
    },
]
```

âš ï¸ **Attention** : Un rÃ©seau plus gros peut dÃ©passer la limite de 65K caractÃ¨res de Shadertoy !

### Tester sur quelques frames

Pour debug rapide, modifier l'extraction de donnÃ©es dans `train_nn.py` :

```python
# Filtrer seulement les 100 premiÃ¨res frames
df = df.filter(pl.col("frame") < 100)
```

## ğŸ”¬ Pipeline technique

### 1. Extraction des pixels

```python
# extract_pixels.py
video â†’ OpenCV â†’ Grayscale â†’ Polars DataFrame â†’ Parquet
```

### 2. EntraÃ®nement NN

```python
# train_nn.py
Parquet â†’ Sample 5% â†’ (frame, x, y, pixel) â†’ PyTorch â†’ Weights
```

### 3. GÃ©nÃ©ration GLSL

```python
# generate_shadertoy_multipass.py
Weights NPZ â†’ Linearize â†’ GLSL array â†’ Buffer A + Image shaders
```

### 4. Multi-pass Shadertoy

```glsl
// Buffer A: Encode weights as texture
const float NN_WEIGHTS[4353] = float[](...);
// Pack into RGBA pixels

// Image: NN forward pass
texelFetch(iChannel0, ...) â†’ Weights â†’ neuralNetwork(frame, x, y) â†’ pixel
```

## ğŸ› Troubleshooting

### EntraÃ®nement trop lent
- RÃ©duire `sample_rate` Ã  0.02
- RÃ©duire `epochs` Ã  10
- Utiliser GPU si disponible

### Shader ne compile pas
- VÃ©rifier que Buffer A est bien connectÃ© Ã  iChannel0 dans Image
- Code trop gros ? RÃ©duire la taille du rÃ©seau
- Erreur syntaxe GLSL ? VÃ©rifier les tableaux constants

### VidÃ©o noire
- Buffer A connectÃ© Ã  iChannel0 ? âœ“
- Compilation rÃ©ussie ? âœ“
- VÃ©rifier les normalisations (frame/max, etc.)

### QualitÃ© mÃ©diocre
- C'est normal ! Le NN est minuscule (4K params pour 1GB de donnÃ©es)
- Pour amÃ©liorer : augmenter taille rÃ©seau, sample_rate, epochs
- Trade-off : qualitÃ© â†” taille du code

### Performance lente sur Shadertoy
- C'est attendu : calcul NN complet par pixel (480Ã—360 = 172K forward passes)
- Impossible Ã  optimiser sans changer l'approche
- Alternative : rÃ©duire rÃ©solution de sortie

## ğŸ’¡ AmÃ©liorations possibles

### NN hybride - PrÃ©dire coefficients DCT
Au lieu de pixels directs, prÃ©dire les coefficients DCT par bloc :
- Input : `(frame, block_x, block_y)`
- Output : 10 coefficients DCT
- Avantages : structure plus compacte, meilleure qualitÃ©

### Downscaling
- EntraÃ®ner sur 240Ã—180 au lieu de 480Ã—360
- Upscale dans le shader (bilinear)
- 4x moins de calculs, qualitÃ© acceptable

### Frames clÃ©s + interpolation
- NN prÃ©dit 1 frame sur 10
- Interpolation linÃ©aire entre frames
- 10x moins de variance temporelle Ã  apprendre

## ğŸ“š Ressources

- [Shadertoy.com](https://www.shadertoy.com) - Plateforme WebGL
- [Bad Apple Wikipedia](https://en.wikipedia.org/wiki/Bad_Apple!!) - Histoire
- [Neural Compression](https://arxiv.org/abs/2001.04451) - Recherche acadÃ©mique
- [SIREN](https://vsitzmann.github.io/siren/) - Implicit Neural Representations

## ğŸ¨ CrÃ©dits

- **Bad Apple!!** Â© Alstroemeria Records / Touhou Project
- **Shadertoy** - IÃ±igo Quilez & Pol Jeremias
- **Concept** - Compression procÃ©durale / Neural implicit functions

## ğŸ“ Notes

**Pourquoi pas de texture custom ?** Shadertoy n'accepte que des textures preset. Cette contrainte force l'embarquement des donnÃ©es directement dans le code GLSL.

**Pourquoi multi-pass ?** Les tableaux GLSL constants ont des limites de taille. Utiliser Buffer A comme "texture de stockage" permet de contourner certaines contraintes.

**Pourquoi si petit ?** Shadertoy limite Ã  ~65K caractÃ¨res de code. Un array de 4353 floats â‰ˆ 50K caractÃ¨res, ce qui laisse de la place pour le code de dÃ©codage.

---

**Amusez-vous bien ! ğŸâœ¨**
